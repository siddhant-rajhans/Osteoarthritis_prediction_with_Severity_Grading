{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2097406,
          "sourceType": "datasetVersion",
          "datasetId": 1257880
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhant-rajhans/Osteoarthritis_prediction_with_Severity_Grading/blob/main/Osteoarthritis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/archive.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/data/\""
      ],
      "metadata": {
        "id": "7xlDRByZjeSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw5Zmk_7l59K",
        "outputId": "87881f19-6b4b-40dd-9e92-ab434aa52a11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import shutil\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from pathlib import Path\n",
        "import random\n",
        "import pickle\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-16T04:17:48.341798Z",
          "iopub.execute_input": "2024-05-16T04:17:48.342304Z",
          "iopub.status.idle": "2024-05-16T04:17:58.917032Z",
          "shell.execute_reply.started": "2024-05-16T04:17:48.342253Z",
          "shell.execute_reply": "2024-05-16T04:17:58.915971Z"
        },
        "trusted": true,
        "id": "_qvmEyCPy_N8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary tools\n",
        "import tensorflow as tf\n",
        "# Check for GPU availability\n",
        "print(\"GPU\", \"available (YESSSS!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "id": "4r-OhTEElEGc",
        "outputId": "ff0c4089-07fa-48e5-d45a-cd91789964cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available (YESSSS!!!!!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration settings\n",
        "class Config:\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    num_epochs = 50\n",
        "    num_classes = 3\n",
        "    learning_rate = 1e-4\n",
        "    model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "    lr_decay = 0.1\n",
        "    patience = 5\n",
        "    batch_size = 32\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:17:58.918893Z",
          "iopub.execute_input": "2024-05-16T04:17:58.919319Z",
          "iopub.status.idle": "2024-05-16T04:17:59.789688Z",
          "shell.execute_reply.started": "2024-05-16T04:17:58.919294Z",
          "shell.execute_reply": "2024-05-16T04:17:59.788785Z"
        },
        "trusted": true,
        "id": "V5dpN3eLy_N9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label mapping for the dataset\n",
        "label_mapping = {0: 0, 1: 1, 2: 1, 3: 2, 4: 2}\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/data/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:17:59.790853Z",
          "iopub.execute_input": "2024-05-16T04:17:59.791161Z",
          "iopub.status.idle": "2024-05-16T04:17:59.796002Z",
          "shell.execute_reply.started": "2024-05-16T04:17:59.791136Z",
          "shell.execute_reply": "2024-05-16T04:17:59.794914Z"
        },
        "trusted": true,
        "id": "MwSvGjG4y_N-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess data\n",
        "def load_data(label_paths, label_map):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    for label in label_paths:\n",
        "        img_list = os.listdir(f\"{dataset_path}{label_paths[label]}\")\n",
        "        image_paths += [f\"{dataset_path}{label_paths[label]}/\" + p for p in img_list]\n",
        "        labels += [label_map[label]] * len(img_list)\n",
        "    return pd.DataFrame({\"Filepath\": image_paths, \"Labels\": labels})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:17:59.79896Z",
          "iopub.execute_input": "2024-05-16T04:17:59.799257Z",
          "iopub.status.idle": "2024-05-16T04:17:59.807804Z",
          "shell.execute_reply.started": "2024-05-16T04:17:59.799224Z",
          "shell.execute_reply": "2024-05-16T04:17:59.80694Z"
        },
        "trusted": true,
        "id": "SFLAbVBmy_N_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and validation data\n",
        "train_data = load_data({0: 'train/0', 2: 'train/2', 3: 'train/3', 4: 'train/4'}, label_mapping)\n",
        "val_data = load_data({0: 'val/0', 2: 'val/2', 3: 'val/3', 4: 'val/4'}, label_mapping)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:17:59.808976Z",
          "iopub.execute_input": "2024-05-16T04:17:59.809258Z",
          "iopub.status.idle": "2024-05-16T04:18:01.020491Z",
          "shell.execute_reply.started": "2024-05-16T04:17:59.809235Z",
          "shell.execute_reply": "2024-05-16T04:18:01.019637Z"
        },
        "trusted": true,
        "id": "oPZhXBc2y_N_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class\n",
        "class KneeOADataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        image = Image.open(img_name)\n",
        "        label = self.df.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.021583Z",
          "iopub.execute_input": "2024-05-16T04:18:01.021911Z",
          "iopub.status.idle": "2024-05-16T04:18:01.028823Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.021887Z",
          "shell.execute_reply": "2024-05-16T04:18:01.027834Z"
        },
        "trusted": true,
        "id": "VApuA_ODy_N_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "pre_processing = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomResizedCrop((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'eval': transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.030094Z",
          "iopub.execute_input": "2024-05-16T04:18:01.030792Z",
          "iopub.status.idle": "2024-05-16T04:18:01.044892Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.030742Z",
          "shell.execute_reply": "2024-05-16T04:18:01.044029Z"
        },
        "trusted": true,
        "id": "IXhkYPT9y_N_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(KneeOADataset(train_data, transform=pre_processing['train']), batch_size=config.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(KneeOADataset(val_data, transform=pre_processing['eval']), batch_size=config.batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.046099Z",
          "iopub.execute_input": "2024-05-16T04:18:01.046351Z",
          "iopub.status.idle": "2024-05-16T04:18:01.054788Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.04633Z",
          "shell.execute_reply": "2024-05-16T04:18:01.053902Z"
        },
        "trusted": true,
        "id": "620XU9_Ry_OA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.27833Z",
          "iopub.execute_input": "2024-05-16T04:18:01.278652Z",
          "iopub.status.idle": "2024-05-16T04:18:01.285811Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.278626Z",
          "shell.execute_reply": "2024-05-16T04:18:01.284745Z"
        },
        "trusted": true,
        "id": "vW5IY4Rcy_OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "model = config.model\n",
        "model.fc = nn.Linear(model.fc.in_features, config.num_classes)\n",
        "criterion = config.criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=config.patience, factor=config.lr_decay, verbose=True)\n",
        "device = config.device\n",
        "model = model.to(device)\n",
        "best_model_params_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/models/', 'best_model_params.pt')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.055863Z",
          "iopub.execute_input": "2024-05-16T04:18:01.056234Z",
          "iopub.status.idle": "2024-05-16T04:18:01.275593Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.056209Z",
          "shell.execute_reply": "2024-05-16T04:18:01.274508Z"
        },
        "trusted": true,
        "id": "DYuAV7f5y_OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65c07f7-ac43-481b-c6f6-38c2abd8180b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "q4iYJNmKN3Rd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, val_loader, criterion, device):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  preds, true_labels = [], []\n",
        "  val_losses = []  # Initialize list to store validation losses\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * inputs.size(0)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      preds.extend(predicted.cpu().numpy())\n",
        "      true_labels.extend(labels.cpu().numpy())\n",
        "      val_losses.append(loss.item() / len(inputs))  # Track loss per batch\n",
        "\n",
        "  accuracy = accuracy_score(true_labels, preds)\n",
        "  f1 = f1_score(true_labels, preds, average='weighted')\n",
        "  cm = confusion_matrix(true_labels, preds)  # Calculate confusion matrix\n",
        "  return total_loss / len(val_loader.dataset), accuracy, f1, val_losses, true_labels, preds, cm\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.28696Z",
          "iopub.execute_input": "2024-05-16T04:18:01.287258Z",
          "iopub.status.idle": "2024-05-16T04:18:01.300621Z",
          "shell.execute_reply.started": "2024-05-16T04:18:01.287235Z",
          "shell.execute_reply": "2024-05-16T04:18:01.299658Z"
        },
        "trusted": true,
        "id": "wSYC7XKPy_OA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vmr6OfjuSo-",
        "outputId": "9644e343-7170-444c-94e2-de69dec12b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.4 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "YPM097o0uIo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping callback configuration\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    min_delta=0.001,  # Minimum improvement threshold\n",
        "    patience=3,  # Stop training after 5 epochs without improvement\n",
        "    verbose=True,  # Print information at each validation check\n",
        "    mode='min'  # Track minimum validation loss\n",
        ")"
      ],
      "metadata": {
        "id": "nBHpVsysuweV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(epochs, model, train_loader, val_loader, optimizer, criterion, scheduler, device):\n",
        "  best_acc = 0\n",
        "  early_stop_count = 0\n",
        "  patience = 3\n",
        "  train_losses = []\n",
        "  val_accuracies = []\n",
        "  val_losses = []  # Initialize val_losses list here\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "    # Train model\n",
        "    train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validate model\n",
        "    val_loss, val_acc, val_f1, val_losses_ = validate_model(model, val_loader, criterion, device)\n",
        "    val_losses.extend(val_losses_)  # Accumulate validation losses from batches\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    # Early Stopping Logic\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(model.state_dict(), best_model_params_path)\n",
        "      print('Model improved and saved')\n",
        "      early_stop_count = 0\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "\n",
        "    # Stop training if validation accuracy doesn't improve for 'patience' epochs\n",
        "    if early_stop_count >= patience:\n",
        "      print(f'Early stopping triggered after {patience} epochs without improvement')\n",
        "      break\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    print(f\"Epoch {epoch + 1} - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Val accuracy: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "  return train_losses, val_accuracies  # Return training and validation metrics for plotting\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T04:18:01.301612Z",
          "iopub.execute_input": "2024-05-16T04:18:01.301929Z"
        },
        "trusted": true,
        "id": "hG-yt3V6y_OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(config.num_epochs, model, train_loader, val_loader, optimizer, criterion, scheduler, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebQTsui0u2C0",
        "outputId": "7271b75d-828c-4eeb-d5fd-3604e6c2307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [05:21<00:00,  4.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model improved and saved\n",
            "Epoch 1 - Train loss: 0.7696, Val loss: 0.6173, Val accuracy: 0.7325, Val F1: 0.7236\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Train loss: 0.7224, Val loss: 0.8297, Val accuracy: 0.6716, Val F1: 0.6272\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:06<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Train loss: 0.6922, Val loss: 0.6992, Val accuracy: 0.7028, Val F1: 0.6675\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:09<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model improved and saved\n",
            "Epoch 4 - Train loss: 0.6744, Val loss: 0.5898, Val accuracy: 0.7533, Val F1: 0.7324\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:08<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model improved and saved\n",
            "Epoch 5 - Train loss: 0.6598, Val loss: 0.5372, Val accuracy: 0.7727, Val F1: 0.7673\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:08<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Train loss: 0.6330, Val loss: 0.5507, Val accuracy: 0.7652, Val F1: 0.7695\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:08<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Train loss: 0.6274, Val loss: 0.5646, Val accuracy: 0.7652, Val F1: 0.7580\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:09<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model improved and saved\n",
            "Epoch 8 - Train loss: 0.6225, Val loss: 0.5288, Val accuracy: 0.7771, Val F1: 0.7734\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:08<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Train loss: 0.6080, Val loss: 0.6072, Val accuracy: 0.7489, Val F1: 0.7435\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:09<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model improved and saved\n",
            "Epoch 10 - Train loss: 0.5943, Val loss: 0.4903, Val accuracy: 0.8098, Val F1: 0.8076\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:09<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Train loss: 0.5657, Val loss: 0.6322, Val accuracy: 0.7325, Val F1: 0.7386\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:09<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Train loss: 0.5903, Val loss: 0.6336, Val accuracy: 0.7459, Val F1: 0.7516\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [01:13<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered after 3 epochs without improvement\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.7696063952333123,\n",
              "  0.7224470306430343,\n",
              "  0.6921510440962655,\n",
              "  0.6743607769955645,\n",
              "  0.6597793535065671,\n",
              "  0.6329748149857316,\n",
              "  0.6273878895924037,\n",
              "  0.6225333035445677,\n",
              "  0.6080422957167219,\n",
              "  0.5942739924937108,\n",
              "  0.5657457730977694,\n",
              "  0.5902754584813864,\n",
              "  0.5810581303106358],\n",
              " [])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data loading\n",
        "test_data = load_data({0: 'test/0', 2: 'test/2', 3: 'test/3', 4: 'test/4'}, label_mapping)\n",
        "test_loader = DataLoader(KneeOADataset(test_data, transform=pre_processing['eval']), batch_size=config.batch_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "UQEhtIuuy_OB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model and evaluate on test set\n",
        "model.load_state_dict(torch.load(best_model_params_path))\n",
        "test_loss, test_acc, test_f1, val_losses = validate_model(model, test_loader, criterion, device)\n",
        "print(f'Test accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "BlkGyhymy_OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, save_path):\n",
        "    torch.save(model.state_dict(), save_path)  # Save model state dictionary\n",
        "\n",
        "# After training loop\n",
        "save_model(model, \"/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/models/saved_model.pt\")  # Replace \"saved_model.pt\" with your desired path"
      ],
      "metadata": {
        "id": "4Q_8043F1r2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "model = config.model\n",
        "model.fc = nn.Linear(model.fc.in_features, config.num_classes)\n",
        "criterion = config.criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=config.patience, factor=config.lr_decay, verbose=True)\n",
        "device = config.device\n",
        "model = model.to(device)\n",
        "best_model_params_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/models/', 'best_model_params.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZwLcmVDL5Sg",
        "outputId": "2efe9b90-4c68-46cb-f37e-cad2be0fd7c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"saved_model.pt\" with your actual saved model path\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/OsteoArthritis/models/saved_model.pt\"\n",
        "model = config.model  # Assuming you have the model class defined in your `Config` class\n",
        "\n",
        "# Use 'eval' transformation for consistency with training preprocessing\n",
        "transform = pre_processing['eval']\n",
        "\n",
        "# Load the model state dictionary\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "IjeqKBqczzw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12592cc4-a33d-422b-9148-d325d26a900c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have already loaded the test data using `test_data` and `test_loader`\n",
        "test_loss, test_acc, test_f1, test_losses, test_true_labels, test_preds, test_cm = validate_model(model, test_loader, config.criterion, config.device)\n",
        "\n",
        "print(f'Test accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkBJVsBoEX_m",
        "outputId": "f6b09716-5fb0-4f89-dc6b-15625895be47"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8037, Test F1: 0.7999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get predictions and true labels from the `validate_model` function output\n",
        "_, true_labels, preds = test_losses\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# (Optional) Plot the confusion matrix using libraries like seaborn or matplotlib\n",
        "sns.heatmap(cm, annot=True, fmt='d')  # Using seaborn for heatmap visualization\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MI2jReHdHPiL",
        "outputId": "4ac41923-8ba0-499c-dca0-e9c64bd303f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-39b3d411d920>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get predictions and true labels from the `validate_model` function output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VwsUVqucMh2b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}